from datetime import datetime as dtime
from glob import glob
import numpy as np
import os
import pandas as pd
import re

# Extra analysis package
from sat_utils import mls

from ginput.common_utils import mod_utils
from ginput.priors.backend_analysis import backend_utils as butils


class MLSMatchError(Exception):
    def __init__(self, dir_dict_key):
        datestr = dir_dict_key[0].strftime('%Y-%m-%d')
        lonstr = mod_utils.format_lon(dir_dict_key[1])
        latstr = mod_utils.format_lat(dir_dict_key[2])
        msg = 'Could not match MLS profile on {} at {}, {} to .map file'.format(datestr, lonstr, latstr)
        super(MLSMatchError, self).__init__(msg)


def write_mls_profile_list(mls_dirs, mls_specie, list_file, min_num_pts=10, every_n_days=1, every_n_profs=1):
    with open(list_file, 'w') as wobj:
        wobj.write('DATES,LAT,LON\n')
        for this_dir in mls_dirs:
            mls_files = sorted(glob(os.path.join(this_dir, 'MLS*.he5')))
            mls_files = mls_files[::every_n_days]

            pbar = mod_utils.ProgressBar(len(mls_files), prefix='MLS file', style='counter')
            for i, f in enumerate(mls_files):
                pbar.print_bar(i)
                profiles = mls.read_mls_profiles(f, mls_specie)
                xx = np.sum(~np.isnan(profiles), axis=1) >= min_num_pts
                profiles = profiles[xx]
                prof_indices = np.arange(xx.size)[xx]

                timestamps = profiles.coords['time'].to_pandas()
                lines = ''

                # This will one added on every nth profile. After we make a profile, it gets one subtracted so we
                # don't add another one until the next nth profile. However, if we skip one because it isn't a good
                # profile, this doesn't get subtracted, so it will try to make the right number of profiles.
                profs_to_make = 0
                for date, lat, lon, index, is_good in zip(timestamps, profiles.coords['lat'], profiles.coords['lon'],
                                                          prof_indices, xx):
                    if index % every_n_profs == 0:
                        profs_to_make += 1

                    if profs_to_make == 0:
                        continue
                    elif not is_good:
                        continue

                    lines += '{date},{lat:.3f},{lon:.3f} # {filename}, profile {profnum}\n'.format(
                        date=date.strftime('%Y-%m-%d'), lat=lat.item(), lon=lon.item(), filename=os.path.basename(f),
                        profnum=index
                    )
                    profs_to_make -= 1
                wobj.write(lines)

            pbar.finish()


def match_mls_prior_profiles(mls_dir, priors_dirs, mls_list, mls_var, out_pres='mls', allow_missing=False):
    """
    Matches profiles from the MLS instrument to prior profiles

    :param mls_dir: directory containing MLS .he5 files in subdirectories organized by year
    :type mls_dir: str

    :param priors_dirs: a list of all directories containing .map files to match
    :type priors_dirs: list(str)

    :param mls_list: the list file generated by :func:`write_mls_profile_list` of MLS profiles, what file they came
     from, and the profile number.
    :type mls_list: str

    :param mls_var: the variable to read from the MLS files, as understood by :func:`mls.read_mls_profiles` as the
     ``specie`` argument. That is, it must be the name of a dataset in the observation (not a priori) Data Fields group
     of the file.
    :type mls_var: str

    :param out_pres: string determining whether the output profiles are placed on the MLS pressures ("mls") or the prior
     pressures ("prior"). The former uses a least-squares estimate as recommended by the MLS user guide, rather than a
     simple interpolation, but may encounter errors due to singular matrices in the least-squares estimate. The latter
     does a simple log-log interpolation of the MLS data to the priors' pressure levels.
    :type out_pres: str

    :param allow_missing: by default, an error is raised if a .map file cannot be found for an MLS profile. Set this
     to ``True`` to skip that MLS profile instead.
    :type allow_missing: bool

    :return: a dictionary with "mls" as an array of MLS profiles, "priors" as an array of matched prior profiles, and
     "pressure" as the array of pressure levels that the first two arrays are arranged on. All arrays have dimensions of
     profiles-by-levels.
    :rtype: dict
    :raises MLSMatchError: if ``allow_missing`` is ``False`` and an MLS profile could not be matched to a .map file.
    """
    # Since there's multiple MLS files. I recorded what file and index each profile in the list file came from, so that
    # will actually make it easier to match up the profiles. We'll need to read the profiles from the right files, find
    # the right times to compare to, then either interpolate the MLS profiles to the priors or use the least-squares
    # estimate in the MLS user guide.
    def mls_file_name(prof_dict):
        yr = prof_dict['date'].strftime('%Y')
        return os.path.join(mls_dir, yr, prof_dict['mls_file'])

    # List profiles to read
    profs = []
    with open(mls_list, 'r') as fobj:
        # discard the header
        fobj.readline()
        for line in fobj:
            prof_dict = dict()
            prof_info, mls_info = line.split('#')
            date_str, lat_str, lon_str = prof_info.split(',')
            prof_dict['date'] = dtime.strptime(date_str, '%Y-%m-%d')
            prof_dict['lon'] = float(lon_str)
            prof_dict['lat'] = float(lat_str)

            mls_file, mls_prof_str = mls_info.split(',')
            prof_dict['mls_file'] = mls_file.strip()
            prof_dict['mls_ind'] = int(re.search(r'\d+', mls_prof_str).group())
            profs.append(prof_dict)

    # First build a dictionary mapping date/lat/lon to the prior directories
    prior_dirs_dict = dict()
    for pdir in priors_dirs:
        k = butils.get_date_lon_lat_from_dirname(pdir)
        if k in prior_dirs_dict:
            raise RuntimeError('{} already exists as a key in the prior dirs dict!'.format(k))
        prior_dirs_dict[k] = pdir

    # Read MLS and prior profiles simultaneously
    mls_profs_list = []
    prior_prof_list = []
    pres_list = []
    last_mls_file = None
    n_missing_files = 0

    pbar = mod_utils.ProgressBar(len(profs), style='counter', prefix='Matching profile')
    for iprof, prof in enumerate(profs):
        pbar.print_bar(iprof)
        this_mls_file = mls_file_name(prof)
        if this_mls_file != last_mls_file:
            print('\n  Must load new MLS file: {} != {}'.format(this_mls_file, last_mls_file))
            last_mls_file = mls_file_name(prof)
            mls_prof_array = mls.read_mls_profiles(this_mls_file, mls_var)

        this_mls_prof = mls_prof_array[prof['mls_ind']]

        # Round the MLS profile time to the nearest 3 hours (may need to fix/skip those rounding to the next day)
        # Read the .map file for that hour, store the profile and pressure.
        mls_time = pd.Timestamp(this_mls_prof.time.item())
        mls_prior_time = mls_time.round('3H')
        if mls_prior_time.day != mls_time.day:
            # The way we run the priors, priors are only generated for the day of the observation. So if we end up
            # rounding to the next day, we likely will not have those priors, so we use the last prior we have.
            mls_prior_time -= pd.Timedelta(hours=3)

        # Construct the key for the directory - (date, lon, lat). Lon and lat are rounded to 2 decimal places
        prior_lon = round(prof['lon'], 2)
        prior_lat = round(prof['lat'], 2)
        dir_key = (mls_prior_time.replace(hour=0), prior_lon, prior_lat)
        try:
            prior_dir = prior_dirs_dict[dir_key]
        except KeyError as err:
            n_missing_files += 1
            if allow_missing:
                continue
            else:
                raise MLSMatchError

        # find the map file that is for the right hour.
        avail_map_files = glob(os.path.join(prior_dir, '*.map'))
        map_pattern = '{}00.map'.format(mls_prior_time.strftime('%H'))
        map_file = [f for f in avail_map_files if f.endswith(map_pattern)]
        if len(map_file) != 1:
            raise RuntimeError('Failed to find the .map file for the right hour')

        map_file = map_file[0]
        map_data = mod_utils.read_map_file(map_file, as_dataframes=False)['profile']

        this_prior_prof = map_data[mls_var.lower()]
        this_prior_pres = map_data['Pressure']

        # According to the MLS data guide, the proper way to compare MLS to a high resolution model is to simulate the
        # profile MLS would sample if it measured the high res profile, rather than interpolating the MLS profile to
        # the high resolution profile. However, that sometimes results in singular matrix errors (yippee)
        if out_pres == 'mls':
            this_prior_prof = mls.mls_least_square_interp(this_mls_prof.pressure, this_prior_pres, this_prior_prof, out_pres='mls')
            this_pres = this_mls_prof.pressure
            this_mls_prof = this_mls_prof.data
        elif out_pres == 'prior':
            interp_p = np.flipud(np.log(this_mls_prof.pressure.data))
            interp_data = np.flipud(np.log(this_mls_prof.data))
            this_mls_prof = np.interp(np.log(this_prior_pres), interp_p, interp_data)
            this_mls_prof = np.exp(this_mls_prof)
            this_pres = this_prior_pres
        else:
            raise ValueError('out_pres must be one of "mls" or "prior"')

        mls_profs_list.append(this_mls_prof)
        prior_prof_list.append(this_prior_prof)
        pres_list.append(this_pres)

    pbar.finish()
    if allow_missing:
        print('{}/{} listed profiles could not be matched with .map files'.format(n_missing_files, len(profs)))

    out_dict = dict()
    out_dict['mls'] = np.array(mls_profs_list)
    out_dict['priors'] = np.array(prior_prof_list)
    out_dict['pressure'] = np.array(pres_list)
    return out_dict
